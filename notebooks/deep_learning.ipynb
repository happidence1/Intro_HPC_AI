{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c290f7b8",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "\n",
    "**ARCATS Workshop**\n",
    "\n",
    "Welcome! In this notebook, you'll learn the basics of deep learning with **PyTorch**. We’ll cover:\n",
    "- Tensors\n",
    "- Neural networks\n",
    "- Training on simple datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bc6471",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "Deep learning is a type of machine learning that uses **neural networks** to learn from data. PyTorch is a popular library for building and training these models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590a54dd",
   "metadata": {},
   "source": [
    "## 2. Tensors in PyTorch\n",
    "Tensors are like NumPy arrays, but optimized for GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "047bbbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7f54b2d-9d62-42f5-abad-22a7bcf8b492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor x:\n",
      " tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor\n",
    "x = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "print(\"Tensor x:\\n\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d94926f8-7e30-404b-b0f7-46348aa3b1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x + x =\n",
      " tensor([[2., 4.],\n",
      "        [6., 8.]])\n",
      "x * 2 =\n",
      " tensor([[2., 4.],\n",
      "        [6., 8.]])\n"
     ]
    }
   ],
   "source": [
    "# Basic operations\n",
    "print(\"x + x =\\n\", x + x)\n",
    "print(\"x * 2 =\\n\", x * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09bd7f9",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Create a 3x3 tensor of random numbers with `torch.rand` and multiply it by 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f759c3b5-a37e-4ce7-951e-46a48e79fb81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a303cb65",
   "metadata": {},
   "source": [
    "## 3. Building a Simple Neural Network\n",
    "We’ll use a small neural network to classify points in the **Iris dataset**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca30fb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c74a7dfe-f419-49c3-8859-bd340c0c2945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d91bcea-950d-433c-a0f5-971493e86de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1e1760b-29e0-45e5-a8f2-397f48494723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensors\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "889a377c-1319-49ff-9d20-6bee91a7f888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 16)\n",
    "        self.fc2 = nn.Linear(16, 3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4141cd77-e97d-49c4-8d67-20d6cbc48262",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7180f304-0952-4aea-9f24-c28d88ca7bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36ca801e-aaba-4c2b-8b59-69c6b8a2b48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training loss: 0.17436008155345917\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(50):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(\"Final training loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2a37ac",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Try changing the number of hidden units in `fc1` (e.g., 32 instead of 16). Does accuracy improve?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54fe0a1",
   "metadata": {},
   "source": [
    "## 4. Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6be09068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test)\n",
    "    predictions = torch.argmax(test_outputs, dim=1)\n",
    "    accuracy = (predictions == y_test).float().mean()\n",
    "    print(\"Test Accuracy:\", accuracy.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23163f7b",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Change the optimizer from `Adam` to `SGD` and see how performance changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5cbfc1",
   "metadata": {},
   "source": [
    "## 5. Deep Learning on Images (MNIST)\n",
    "Now let’s use a neural network on the **MNIST dataset** of handwritten digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f5edcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab59b9fc-b779-438a-beb0-6650719b266d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6badd65c-5513-433d-bfbe-36fc8f066796",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "808912a1-5740-4ac3-969a-3c7278c84381",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8459ebec-6048-459b-8039-75e5ebdd02cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "class MNISTNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44c68050-148d-4d03-ab12-43680bd2ea26",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_model = MNISTNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(mnist_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3683603-a1d0-456c-833a-1169fbebe6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Loss: 0.3861\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1  # number of epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()           # reset gradients\n",
    "        outputs = mnist_model(images)  # forward pass\n",
    "        loss = criterion(outputs, labels)  # compute loss\n",
    "        loss.backward()                 # backpropagate\n",
    "        optimizer.step()                # update weights\n",
    "\n",
    "        running_loss += loss.item()     # accumulate loss\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af72cf23-d1b6-48c0-aea9-0557b523171d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 94.03%\n"
     ]
    }
   ],
   "source": [
    "mnist_model.eval()  # set model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # no need to compute gradients\n",
    "    for images, labels in test_loader:\n",
    "        outputs = mnist_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)  # get class with highest score\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4885b43",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "Change the number of epochs `num_epochs` and train for several epochs. How does accuracy improve?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9efea73-790a-4194-b683-1e80e7ef8b32",
   "metadata": {},
   "source": [
    "## 5. Convolutional Neural Networks (CNNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ffdaf14-d74f-4cb3-91c5-f6e05540f875",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTCNN, self).__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)  # after 2 pooling layers, 28x28 -> 7x7\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b9de73d-f795-4fa7-8e6c-a7ecb22b15d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model, loss, optimizer\n",
    "mnist_cnn = MNISTCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(mnist_cnn.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77aaddd1-f5d3-4bb5-b4f0-6d5f004d92f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Loss: 0.1597\n"
     ]
    }
   ],
   "source": [
    "# Training loop (1 epoch for example)\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = mnist_cnn(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af070f68-de0a-4d73-a118-87f0a0dbe00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 98.46%\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy\n",
    "mnist_cnn.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = mnist_cnn(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe473637",
   "metadata": {},
   "source": [
    "## 6. Summary\n",
    "You learned:\n",
    "- Tensors in PyTorch\n",
    "- Building and training a simple neural network\n",
    "- Evaluating performance\n",
    "- Training a neural net on images (MNIST) with Fully connected Neural Network\n",
    "- Use Convolutional Neural Networks (CNNs) for better image accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
